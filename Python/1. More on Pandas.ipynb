{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking:\n",
    "\n",
    "Ranking is closely related to sorting, assigning ranks from one through the number of valid data points in an array.\n",
    "By default rank breaks ties by assigning each group the mean rank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6.5\n",
      "1    1.0\n",
      "2    6.5\n",
      "3    4.5\n",
      "4    3.0\n",
      "5    2.0\n",
      "6    4.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "obj = pd.Series([7, -5, 7, 4, 2, 0, 4])\n",
    "print(obj.rank())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6.0\n",
      "1    1.0\n",
      "2    7.0\n",
      "3    4.0\n",
      "4    3.0\n",
      "5    2.0\n",
      "6    5.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Ranks can also be assigned according to the order they’re observed in the data:\n",
    "import pandas as pd\n",
    "obj = pd.Series([7, -5, 7, 4, 2, 0, 4])\n",
    "print(obj.rank(method='first'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.5\n",
      "1    7.0\n",
      "2    1.5\n",
      "3    3.5\n",
      "4    5.0\n",
      "5    6.0\n",
      "6    3.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#You can rank in descending order, too:\n",
    "obj = pd.Series([7, -5, 7, 4, 2, 0, 4])\n",
    "print(obj.rank(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3.0\n",
      "1    7.0\n",
      "2    3.0\n",
      "3    5.0\n",
      "4    6.0\n",
      "5    3.0\n",
      "6    5.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#You can rank in descending order, too:\n",
    "obj = pd.Series([7, -5, 7, 4, 2, 7, 4])\n",
    "#print(obj.rank(ascending=False))\n",
    "\n",
    "print(obj.rank(ascending=False, method='max')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    7.0\n",
      "2    1.0\n",
      "3    4.0\n",
      "4    6.0\n",
      "5    1.0\n",
      "6    4.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#You can rank in descending order, too:\n",
    "\n",
    "print(obj.rank(ascending=False, method='min')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Frame: \n",
      "    a    b    c\n",
      "0  0  4.3 -2.0\n",
      "1  1  7.0  5.0\n",
      "2  0 -3.0  8.0\n",
      "3  1  2.0 -2.5\n",
      "Rank ROw wise: \n",
      "      a    b    c\n",
      "0  1.5  3.0  2.0\n",
      "1  3.5  4.0  3.0\n",
      "2  1.5  1.0  4.0\n",
      "3  3.5  2.0  1.0\n",
      "Rank Column wise: \n",
      "      a    b    c\n",
      "0  2.0  3.0  1.0\n",
      "1  1.0  3.0  2.0\n",
      "2  2.0  1.0  3.0\n",
      "3  2.0  3.0  1.0\n"
     ]
    }
   ],
   "source": [
    "#DataFrame can compute ranks over the rows or the columns:\n",
    "\n",
    "frame = pd.DataFrame({'b': [4.3, 7, -3, 2], 'a': [0, 1, 0, 1],\n",
    "                   'c': [-2, 5, 8, -2.5]})\n",
    "\n",
    "print(\"Original Data Frame: \\n\",frame)\n",
    "\n",
    "print(\"Rank ROw wise: \\n\",frame.rank(axis=0))\n",
    "\n",
    "print(\"Rank Column wise: \\n\",frame.rank(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axis indexes with duplicate values\n",
    "\n",
    "Up until now all of the examples We’ve seen, we have had unique axis labels (index values). While many pandas functions (like reindex) require that the labels be unique, it’s not mandatory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame[\"a\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "a    1\n",
      "b    2\n",
      "b    3\n",
      "c    4\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "obj = pd.Series(range(5), index=['a', 'a', 'b', 'b', 'c'])\n",
    "\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#The index’s is_unique property can tell you whether its values are unique or not:\n",
    "\n",
    "print(obj.index.is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Index: \n",
      " a    0\n",
      "a    1\n",
      "dtype: int32\n",
      "Unique Index: \n",
      " 4\n"
     ]
    }
   ],
   "source": [
    "#Data selection is one of the main things that behaves differently with duplicates. \n",
    "#Indexing a value with multiple entries returns a Series while single entries return a scalar value:\n",
    "\n",
    "print(\"Duplicate Index: \\n\",obj['a'])\n",
    "print(\"Unique Index: \\n\",obj['c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame with Duplicate Index :\n",
      "           a         a         b\n",
      "a -1.343517 -0.715283 -0.673420\n",
      "a -0.039239  1.948642 -1.075378\n",
      "b -0.473371 -0.335999  0.056634\n",
      "b -0.626049 -0.915633  0.546471\n",
      "Fetch Duplicate index: \n",
      "           a         a         b\n",
      "a -1.343517 -0.715283 -0.673420\n",
      "a -0.039239  1.948642 -1.075378\n"
     ]
    }
   ],
   "source": [
    "#The same logic extends to indexing rows in a DataFrame:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(np.random.randn(4, 3), \n",
    "                  index=['a', 'a', 'b', 'b'],\n",
    "                  columns=['a', 'a', 'b'])\n",
    "\n",
    "print(\"Data Frame with Duplicate Index :\\n\",df)\n",
    "\n",
    "print(\"Fetch Duplicate index: \\n\",df.loc['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing and Computing Descriptive Statistics\n",
    "\n",
    "pandas objects are equipped with a set of common mathematical and statistical methods. Most of these fall into the category of reductions or summary statistics, methods that extract a single value (like the sum or mean) from a Series or a Series of values from the rows or columns of a DataFrame. Compared with the equivalent methods of vanilla\n",
    "NumPy arrays, they are all built from the ground up to exclude missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Frame is: \n",
      "     one  two\n",
      "a  1.40  NaN\n",
      "b  7.10 -4.5\n",
      "c   NaN  NaN\n",
      "d  0.75 -1.3\n",
      "Sum is: \n",
      " one    9.25\n",
      "two   -5.80\n",
      "dtype: float64\n",
      "Sum over the rows : \n",
      " a    1.40\n",
      "b    2.60\n",
      "c    0.00\n",
      "d   -0.55\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5],\n",
    "                [np.nan, np.nan], [0.75, -1.3]],\n",
    "               index=['a', 'b', 'c', 'd'],\n",
    "               columns=['one', 'two'])\n",
    "\n",
    "print(\"Original Data Frame is: \\n\",df)\n",
    "\n",
    "print(\"Sum is: \\n\",df.sum())\n",
    "\n",
    "print(\"Sum over the rows : \\n\",df.sum(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Frame is: \n",
      "     one  two\n",
      "a  1.40  NaN\n",
      "b  7.10 -4.5\n",
      "c   NaN  NaN\n",
      "d  0.75 -1.3\n",
      "Sum with NA: \n",
      " a     NaN\n",
      "b    2.60\n",
      "c     NaN\n",
      "d   -0.55\n",
      "dtype: float64\n",
      "Mean with NA: \n",
      " a      NaN\n",
      "b    1.300\n",
      "c      NaN\n",
      "d   -0.275\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#NA values are excluded unless the entire slice (row or column in this case) is NA. This\n",
    "#can be disabled using the skipna option:\n",
    "print(\"Original Data Frame is: \\n\",df)\n",
    "print(\"Sum with NA: \\n\",df.sum(axis=1, skipna=False))\n",
    "print(\"Mean with NA: \\n\",df.mean(axis=1, skipna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics :\n",
      "             one       two\n",
      "count  3.000000  2.000000\n",
      "mean   3.083333 -2.900000\n",
      "std    3.493685  2.262742\n",
      "min    0.750000 -4.500000\n",
      "25%    1.075000 -3.700000\n",
      "50%    1.400000 -2.900000\n",
      "75%    4.250000 -2.100000\n",
      "max    7.100000 -1.300000\n"
     ]
    }
   ],
   "source": [
    "#producing multiple summary statistics in one shot:\n",
    "\n",
    "print(\"Summary Statistics :\\n\",df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data:\n",
    "\n",
    "Missing data is common in most data analysis applications. One of the goals in designing pandas was to make working with missing data as painless as possible. For example, all of the descriptive statistics on pandas objects exclude missing data.\n",
    "\n",
    "pandas uses the floating point value NaN (Not a Number) to represent missing data in both floating as well as in non-floating point arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, None, 3, 4], dtype=object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#None, a Python singleton object that is often used for missing data in Python code. \n",
    "#Because it is a Python object, None cannot be used in any arbitrary NumPy/Pandas array, \n",
    "#but only in arrays with data type 'object' (i.e., arrays of Python objects):\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "vals1 = np.array([1, None, 3, 4])\n",
    "vals1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NaN: Missing numerical data\n",
    "\n",
    "#The other missing data representation, NaN (acronym for Not a Number), \n",
    "#is different; it is a special floating-point value recognized by all systems \n",
    "#that use the standard IEEE floating-point representation:\n",
    "\n",
    "vals2 = np.array([1, np.nan, 3, 4]) \n",
    "vals2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that NumPy chose a native floating-point type for this array: this means that unlike the object array from before, this array supports fast operations pushed into compiled code. You should be aware that NaN is a bit like a data virus–it infects any other object it touches. Regardless of the operation, the result of arithmetic with NaN will be another NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, nan, nan)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note that this means that aggregates over the values are well defined \n",
    "#(i.e., they don't result in an error) but not always useful:\n",
    "\n",
    "vals2.sum(), vals2.min(), vals2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.0, 1.0, 4.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NumPy does provide some special aggregations that will ignore these missing values:\n",
    "\n",
    "np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaN and None in Pandas:\n",
    "\n",
    "NaN and None both have their place, and Pandas is built to handle the two of them nearly interchangeably, converting between them where appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "dtype: int64\n",
      "0    1.0\n",
      "1    2.0\n",
      "2    NaN\n",
      "dtype: float64\n",
      "0    True\n",
      "1    True\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1     NaN\n",
       "2    True\n",
       "3    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "print(pd.Series([1,2]))\n",
    "print(pd.Series([1,2,None]))\n",
    "#pd.Series([1, np.nan, 2, None])\n",
    "print(pd.Series([True, True]))\n",
    "pd.Series([True, np.nan, True, None])\n",
    "#pd.Series([True, True])\n",
    "#pd.Series([1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas automatically type-casts when NA values are present. For example, if we set a value in an integer array to np.nan, it will automatically be upcast to a floating-point type to accommodate the NA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "dtype: int32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.Series(range(2), dtype=int)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] = None\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in addition to casting the integer array to floating point, Pandas automatically converts the None to a NaN value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typeclass\t    Conversion When Storing NAs\t    NA Sentinel Value\n",
    "\n",
    "#floating\t          No change\t                                         np.nan\n",
    "#object\t              No change\t                                         None or np.nan\n",
    "#integer\t          Cast to float64\t                                 np.nan\n",
    "#boolean\t          Cast to object\t                                 None or np.nan\n",
    "\n",
    "\n",
    "Keep in mind that in Pandas, string data is always stored with an object dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operating on Null Values\n",
    "\n",
    "As we have seen, Pandas treats None and NaN as essentially interchangeable for indicating missing or null values. To facilitate this convention, there are several useful methods for detecting, removing, and replacing null values in Pandas data structures. They are:\n",
    "\n",
    "#isnull(): Generate a boolean mask indicating missing values\n",
    "#notnull(): Opposite of isnull()\n",
    "#dropna(): Return a filtered version of the data\n",
    "#fillna(): Return a copy of the data with missing values filled or imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    3.0\n",
       "3    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.Series([1,2,3,np.nan])\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series: \n",
      " 0    ABC\n",
      "1    XYZ\n",
      "2    NaN\n",
      "3    123\n",
      "dtype: object\n",
      "Null Check: \n",
      " 0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "dtype: bool\n",
      "Another method - Null Check: \n",
      " 0     True\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "##Detecting null values\n",
    "\n",
    "string_data = pd.Series(['ABC', 'XYZ', np.nan, '123'])\n",
    "\n",
    "print(\"Original Series: \\n\",string_data)\n",
    "\n",
    "print(\"Null Check: \\n\",string_data.isnull())\n",
    "\n",
    "print(\"Another method - Null Check: \\n\",string_data.notnull())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Series: \n",
      " 0    None\n",
      "1     XYZ\n",
      "2     NaN\n",
      "3     123\n",
      "dtype: object\n",
      "Null Check: \n",
      " 0     True\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "dtype: bool\n",
      "Another method - Null Check: \n",
      " 0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Detecting null values\n",
    "#The built-in Python None value is also treated as NA in object arrays:\n",
    "\n",
    "string_data[0] = None\n",
    "\n",
    "print(\"Updated Series: \\n\",string_data)\n",
    "\n",
    "print(\"Null Check: \\n\",string_data.isnull())\n",
    "\n",
    "print(\"Another method - Null Check: \\n\",string_data.notnull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series: \n",
      " 0    1.0\n",
      "1    NaN\n",
      "2    3.5\n",
      "3    NaN\n",
      "4    7.0\n",
      "dtype: float64\n",
      "Drop NA : \n",
      " 0    1.0\n",
      "2    3.5\n",
      "4    7.0\n",
      "dtype: float64\n",
      "Drop NA :\n",
      " 0    1.0\n",
      "2    3.5\n",
      "4    7.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#dropna:  Filter axis labels based on whether values for each label have missing data, with varying thresholds \n",
    "#         for how much missing data to tolerate.\n",
    "\n",
    "data = pd.Series([1, np.nan, 3.5, np.nan, 7])\n",
    "\n",
    "print(\"Original Series: \\n\",data)\n",
    "\n",
    "#data.dropna()\n",
    "\n",
    "print(\"Drop NA : \\n\",data.dropna())\n",
    "\n",
    "#Another method\n",
    "\n",
    "print(\"Drop NA :\\n\",data[data.notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe :\n",
      "      0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  1.0  NaN  NaN\n",
      "2  NaN  NaN  NaN\n",
      "3  NaN  6.5  3.0\n",
      "Drop NA rows :\n",
      "      0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "Drop only rows which has all NA values :\n",
      "      0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  1.0  NaN  NaN\n",
      "3  NaN  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "#You may want to drop rows or columns which are all NA or just those containing any NAs. dropna by default drops\n",
    "#any row containing a missing value:\n",
    "\n",
    "data = pd.DataFrame([[1., 6.5, 3.], [1., np.nan, np.nan],\n",
    "                  [np.nan, np.nan, np.nan], [np.nan, 6.5, 3.]])\n",
    "\n",
    "print(\"Original Dataframe :\\n\",data)\n",
    "\n",
    "\n",
    "print(\"Drop NA rows :\\n\",data.dropna())\n",
    "\n",
    "#Passing how='all' will only drop rows that are all NA:\n",
    "print(\"Drop only rows which has all NA values :\\n\",\n",
    "      data.dropna(how = 'all'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Fram: \n",
      "      0    1    2   4\n",
      "0  1.0  6.5  3.0 NaN\n",
      "1  1.0  NaN  NaN NaN\n",
      "2  NaN  NaN  NaN NaN\n",
      "3  NaN  6.5  3.0 NaN\n",
      "Drop only columns which has all NA values :\n",
      "      0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  1.0  NaN  NaN\n",
      "2  NaN  NaN  NaN\n",
      "3  NaN  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "#Dropping columns in the same way is only a matter of passing axis=1:\n",
    "\n",
    "data[4] = np.nan\n",
    "print(\"Original Data Fram: \\n\",data)\n",
    "\n",
    "print(\"Drop only columns which has all NA values :\\n\",\n",
    "      data.dropna(axis = 1,#(columns)\n",
    "                  how = 'all')) #default is how = 'any'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe :\n",
      "      0    1    2    3\n",
      "0  1.0  6.5  3.0  NaN\n",
      "1  1.0  NaN  NaN  2.0\n",
      "2  NaN  NaN  NaN  NaN\n",
      "3  NaN  6.5  3.0  4.0\n",
      "After thresh: \n",
      "      0    1    2    3\n",
      "0  1.0  6.5  3.0  NaN\n",
      "1  1.0  NaN  NaN  2.0\n",
      "3  NaN  6.5  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "#For finer-grained control, the thresh parameter lets you specify a minimum number of \n",
    "#non-null values for the row/column to be kept:\n",
    "\n",
    "data = pd.DataFrame([[1., 6.5, 3.,np.nan], \n",
    "                     [1., np.nan, np.nan,2],\n",
    "                  [np.nan, np.nan, np.nan,np.nan], \n",
    "                     [np.nan, 6.5, 3.,4]])\n",
    "\n",
    "print(\"Original Dataframe :\\n\",data)\n",
    "\n",
    "\n",
    "print(\"After thresh: \\n\",data.dropna(axis='rows', thresh=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data frame: \n",
      "      0    1    2    3\n",
      "0  1.0  6.5  3.0  NaN\n",
      "1  1.0  NaN  NaN  2.0\n",
      "2  NaN  NaN  NaN  NaN\n",
      "3  NaN  6.5  3.0  4.0\n",
      "Replace NA values with 0: \n",
      "      0    1    2    3\n",
      "0  1.0  6.5  3.0  0.0\n",
      "1  1.0  0.0  0.0  2.0\n",
      "2  0.0  0.0  0.0  0.0\n",
      "3  0.0  6.5  3.0  4.0\n"
     ]
    }
   ],
   "source": [
    "#2. Filling in Missing Data\n",
    "\n",
    "#Rather than filtering out missing data (and potentially discarding other data along with it), \n",
    "#you may want to fill in the “holes” in any number of ways.\n",
    "df = pd.DataFrame([[1., 6.5, 3.,np.nan], \n",
    "                   [1., np.nan, np.nan,2],\n",
    "                  [np.nan, np.nan, np.nan,np.nan], \n",
    "                   [np.nan, 6.5, 3.,4]])\n",
    "print(\"Original Data frame: \\n\",df)\n",
    "print(\"Replace NA values with 0: \\n\",df.fillna(0))\n",
    "\n",
    "#The same interpolation methods available for reindexing can be used with fillna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series :\n",
      " 0    1.0\n",
      "1    NaN\n",
      "2    3.5\n",
      "3    NaN\n",
      "4    7.0\n",
      "dtype: float64\n",
      "Mean:  3.8333333333333335\n",
      "Fill with NA :\n",
      " 0    1.000000\n",
      "1    3.833333\n",
      "2    3.500000\n",
      "3    3.833333\n",
      "4    7.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#With fillna you can do lots of other things with a little creativity. For example, you\n",
    "#might pass the mean or median value of a Series:\n",
    "\n",
    "data = pd.Series([1., np.nan, 3.5, np.nan, 7])\n",
    "\n",
    "print(\"Original Series :\\n\",data)\n",
    "print(\"Mean: \",data.mean())\n",
    "\n",
    "print(\"Fill with NA :\\n\",data.fillna(data.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  1.0  6.5  3.0  NaN\n",
       "1  1.0  6.5  3.0  2.0\n",
       "2  1.0  6.5  3.0  2.0\n",
       "3  1.0  6.5  3.0  4.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward-fill\n",
    "data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  1.0  6.5  3.0  2.0\n",
       "1  1.0  6.5  3.0  2.0\n",
       "2  NaN  6.5  3.0  4.0\n",
       "3  NaN  6.5  3.0  4.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# back-fill\n",
    "data.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading, Storage, and File Formats\n",
    "\n",
    "NumPy, features low-level but extremely fast binary data loading and storage, including support for memory-mapped array.\n",
    "\n",
    "Input and output typically falls into a few main categories: reading text files and other more efficient on-disk formats, loading data from databases, and interacting with network sources like web APIs.\n",
    "\n",
    "pandas features a number of functions for reading tabular data as a DataFrame object.\n",
    "\n",
    "read_csv: Load delimited data from a file, URL, or file-like object. Use comma as default delimiter\n",
    "read_table: Load delimited data from a file, URL, or file-like object. Use tab ('\\t') as default delimiter\n",
    "read_fwf: Read data in fixed-width column format (that is, no delimiters)\n",
    "\n",
    "Few points to remember :\n",
    "\n",
    "##### Indexing: \n",
    "    can treat one or more columns as the returned DataFrame, and whether to get column names from the file, the user, or not at all.\n",
    "##### Type inference and data conversion: T\n",
    "    This includes the user-defined value conversions and custom list of missing value markers.\n",
    "##### Datetime parsing: \n",
    "    includes combining capability, including combining date and time information spread over multiple columns into \n",
    "    a single column in the result.\n",
    "##### Iterating: \n",
    "    support for iterating over chunks of very large files.\n",
    "##### Unclean data issues: \n",
    "    skipping rows or a footer, comments, or other minor things like numeric data with thousands separated by commas.\n",
    "\n",
    "\n",
    "Type inference is one of the more important features of these functions; that means you don’t have to specify which columns are numeric, integer, boolean, or string. Handling dates and other custom types requires a bit more effort, though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Analytics\\Personal\\Machine Learning\\Training\\R\\Dataset\n",
      "C:\\Analytics\\Personal\\Machine Learning\\Training\\R\\Dataset\n"
     ]
    }
   ],
   "source": [
    "#Changing the working directory\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "os.chdir('C:\\\\Analytics\\\\Personal\\\\Machine Learning\\\\Training\\\\R\\\\Dataset')\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Type of mushroom cap-shape cap-surface cap-color bruises     odor  \\\n",
      "0              EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
      "1              EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
      "2              EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
      "3              EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
      "4              EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
      "5              EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES  ALMOND   \n",
      "6              EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES   ANISE   \n",
      "7              EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES   ANISE   \n",
      "8              EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES   ANISE   \n",
      "9              EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES   ANISE   \n",
      "10             EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES   ANISE   \n",
      "11             EDIBLE    CONVEX      SMOOTH     WHITE  BRUISES   ANISE   \n",
      "12             EDIBLE    CONVEX      SMOOTH    YELLOW  BRUISES  ALMOND   \n",
      "13             EDIBLE    CONVEX      SMOOTH    YELLOW  BRUISES  ALMOND   \n",
      "14             EDIBLE    CONVEX      SMOOTH    YELLOW  BRUISES  ALMOND   \n",
      "15             EDIBLE    CONVEX      SMOOTH    YELLOW  BRUISES  ALMOND   \n",
      "16             EDIBLE    CONVEX      SMOOTH    YELLOW  BRUISES  ALMOND   \n",
      "17             EDIBLE    CONVEX      SMOOTH    YELLOW  BRUISES  ALMOND   \n",
      "18             EDIBLE    CONVEX      SMOOTH    YELLOW  BRUISES   ANISE   \n",
      "19             EDIBLE    CONVEX      SMOOTH    YELLOW  BRUISES   ANISE   \n",
      "20             EDIBLE    CONVEX      SMOOTH    YELLOW  BRUISES   ANISE   \n",
      "21             EDIBLE    CONVEX      SMOOTH    YELLOW  BRUISES   ANISE   \n",
      "22             EDIBLE    CONVEX      SMOOTH    YELLOW  BRUISES   ANISE   \n",
      "23             EDIBLE    CONVEX      SMOOTH    YELLOW  BRUISES   ANISE   \n",
      "24             EDIBLE    CONVEX     FIBROUS     WHITE  BRUISES  ALMOND   \n",
      "25             EDIBLE    CONVEX     FIBROUS     WHITE  BRUISES  ALMOND   \n",
      "26             EDIBLE    CONVEX     FIBROUS     WHITE  BRUISES  ALMOND   \n",
      "27             EDIBLE    CONVEX     FIBROUS     WHITE  BRUISES  ALMOND   \n",
      "28             EDIBLE    CONVEX     FIBROUS     WHITE  BRUISES  ALMOND   \n",
      "29             EDIBLE    CONVEX     FIBROUS     WHITE  BRUISES  ALMOND   \n",
      "...               ...       ...         ...       ...      ...     ...   \n",
      "8386           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8387           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8388           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8389           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8390           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8391           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8392           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8393           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8394           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8395           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8396           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8397           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8398           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8399           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8400           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8401           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8402           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8403           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8404           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8405           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8406           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8407           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8408           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8409           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8410           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8411           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8412           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8413           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8414           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "8415           EDIBLE   KNOBBED      SMOOTH     BROWN       NO    NONE   \n",
      "\n",
      "     gill-attachment gill-spacing gill-size gill-color   ...    \\\n",
      "0               FREE      CROWDED    NARROW      WHITE   ...     \n",
      "1               FREE      CROWDED    NARROW      WHITE   ...     \n",
      "2               FREE      CROWDED    NARROW       PINK   ...     \n",
      "3               FREE      CROWDED    NARROW       PINK   ...     \n",
      "4               FREE      CROWDED    NARROW      BROWN   ...     \n",
      "5               FREE      CROWDED    NARROW      BROWN   ...     \n",
      "6               FREE      CROWDED    NARROW      WHITE   ...     \n",
      "7               FREE      CROWDED    NARROW      WHITE   ...     \n",
      "8               FREE      CROWDED    NARROW       PINK   ...     \n",
      "9               FREE      CROWDED    NARROW       PINK   ...     \n",
      "10              FREE      CROWDED    NARROW      BROWN   ...     \n",
      "11              FREE      CROWDED    NARROW      BROWN   ...     \n",
      "12              FREE      CROWDED    NARROW      WHITE   ...     \n",
      "13              FREE      CROWDED    NARROW      WHITE   ...     \n",
      "14              FREE      CROWDED    NARROW       PINK   ...     \n",
      "15              FREE      CROWDED    NARROW       PINK   ...     \n",
      "16              FREE      CROWDED    NARROW      BROWN   ...     \n",
      "17              FREE      CROWDED    NARROW      BROWN   ...     \n",
      "18              FREE      CROWDED    NARROW      WHITE   ...     \n",
      "19              FREE      CROWDED    NARROW      WHITE   ...     \n",
      "20              FREE      CROWDED    NARROW       PINK   ...     \n",
      "21              FREE      CROWDED    NARROW       PINK   ...     \n",
      "22              FREE      CROWDED    NARROW      BROWN   ...     \n",
      "23              FREE      CROWDED    NARROW      BROWN   ...     \n",
      "24              FREE      CROWDED    NARROW      WHITE   ...     \n",
      "25              FREE      CROWDED    NARROW      WHITE   ...     \n",
      "26              FREE      CROWDED    NARROW       PINK   ...     \n",
      "27              FREE      CROWDED    NARROW       PINK   ...     \n",
      "28              FREE      CROWDED    NARROW      BROWN   ...     \n",
      "29              FREE      CROWDED    NARROW      BROWN   ...     \n",
      "...              ...          ...       ...        ...   ...     \n",
      "8386        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8387        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8388        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8389        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8390        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8391        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8392        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8393        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8394        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8395        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8396        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8397        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8398        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8399        ATTACHED        CLOSE     BROAD     ORANGE   ...     \n",
      "8400        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8401        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8402        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8403        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8404        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8405        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8406        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8407        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8408        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8409        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8410        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8411        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8412        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8413        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8414        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "8415        ATTACHED        CLOSE     BROAD      BROWN   ...     \n",
      "\n",
      "     stalk-surface below ring stalk color above ring stalk color below ring  \\\n",
      "0                      SMOOTH                  WHITE                  WHITE   \n",
      "1                      SMOOTH                  WHITE                  WHITE   \n",
      "2                      SMOOTH                  WHITE                  WHITE   \n",
      "3                      SMOOTH                  WHITE                  WHITE   \n",
      "4                      SMOOTH                  WHITE                  WHITE   \n",
      "5                      SMOOTH                  WHITE                  WHITE   \n",
      "6                      SMOOTH                  WHITE                  WHITE   \n",
      "7                      SMOOTH                  WHITE                  WHITE   \n",
      "8                      SMOOTH                  WHITE                  WHITE   \n",
      "9                      SMOOTH                  WHITE                  WHITE   \n",
      "10                     SMOOTH                  WHITE                  WHITE   \n",
      "11                     SMOOTH                  WHITE                  WHITE   \n",
      "12                     SMOOTH                  WHITE                  WHITE   \n",
      "13                     SMOOTH                  WHITE                  WHITE   \n",
      "14                     SMOOTH                  WHITE                  WHITE   \n",
      "15                     SMOOTH                  WHITE                  WHITE   \n",
      "16                     SMOOTH                  WHITE                  WHITE   \n",
      "17                     SMOOTH                  WHITE                  WHITE   \n",
      "18                     SMOOTH                  WHITE                  WHITE   \n",
      "19                     SMOOTH                  WHITE                  WHITE   \n",
      "20                     SMOOTH                  WHITE                  WHITE   \n",
      "21                     SMOOTH                  WHITE                  WHITE   \n",
      "22                     SMOOTH                  WHITE                  WHITE   \n",
      "23                     SMOOTH                  WHITE                  WHITE   \n",
      "24                     SMOOTH                  WHITE                  WHITE   \n",
      "25                     SMOOTH                  WHITE                  WHITE   \n",
      "26                     SMOOTH                  WHITE                  WHITE   \n",
      "27                     SMOOTH                  WHITE                  WHITE   \n",
      "28                     SMOOTH                  WHITE                  WHITE   \n",
      "29                     SMOOTH                  WHITE                  WHITE   \n",
      "...                       ...                    ...                    ...   \n",
      "8386                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8387                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8388                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8389                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8390                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8391                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8392                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8393                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8394                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8395                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8396                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8397                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8398                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8399                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8400                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8401                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8402                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8403                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8404                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8405                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8406                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8407                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8408                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8409                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8410                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8411                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8412                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8413                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8414                   SMOOTH                 ORANGE                 ORANGE   \n",
      "8415                   SMOOTH                 ORANGE                 ORANGE   \n",
      "\n",
      "     veil type  veil color ring number  ring type spore print color  \\\n",
      "0       PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "1       PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "2       PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "3       PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "4       PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "5       PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "6       PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "7       PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "8       PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "9       PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "10      PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "11      PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "12      PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "13      PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "14      PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "15      PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "16      PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "17      PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "18      PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "19      PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "20      PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "21      PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "22      PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "23      PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "24      PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "25      PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "26      PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "27      PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "28      PARTIAL      WHITE          ONE   PENDANT            PURPLE   \n",
      "29      PARTIAL      WHITE          ONE   PENDANT             BROWN   \n",
      "...         ...        ...          ...       ...               ...   \n",
      "8386    PARTIAL     ORANGE          ONE   PENDANT             BROWN   \n",
      "8387    PARTIAL     ORANGE          ONE   PENDANT             BROWN   \n",
      "8388    PARTIAL     ORANGE          ONE   PENDANT            ORANGE   \n",
      "8389    PARTIAL     ORANGE          ONE   PENDANT            ORANGE   \n",
      "8390    PARTIAL     ORANGE          ONE   PENDANT              BUFF   \n",
      "8391    PARTIAL     ORANGE          ONE   PENDANT              BUFF   \n",
      "8392    PARTIAL      BROWN          ONE   PENDANT            YELLOW   \n",
      "8393    PARTIAL      BROWN          ONE   PENDANT            YELLOW   \n",
      "8394    PARTIAL      BROWN          ONE   PENDANT             BROWN   \n",
      "8395    PARTIAL      BROWN          ONE   PENDANT             BROWN   \n",
      "8396    PARTIAL      BROWN          ONE   PENDANT            ORANGE   \n",
      "8397    PARTIAL      BROWN          ONE   PENDANT            ORANGE   \n",
      "8398    PARTIAL      BROWN          ONE   PENDANT              BUFF   \n",
      "8399    PARTIAL      BROWN          ONE   PENDANT              BUFF   \n",
      "8400    PARTIAL     ORANGE          ONE   PENDANT            YELLOW   \n",
      "8401    PARTIAL     ORANGE          ONE   PENDANT            YELLOW   \n",
      "8402    PARTIAL     ORANGE          ONE   PENDANT             BROWN   \n",
      "8403    PARTIAL     ORANGE          ONE   PENDANT             BROWN   \n",
      "8404    PARTIAL     ORANGE          ONE   PENDANT            ORANGE   \n",
      "8405    PARTIAL     ORANGE          ONE   PENDANT            ORANGE   \n",
      "8406    PARTIAL     ORANGE          ONE   PENDANT              BUFF   \n",
      "8407    PARTIAL     ORANGE          ONE   PENDANT              BUFF   \n",
      "8408    PARTIAL      BROWN          ONE   PENDANT            YELLOW   \n",
      "8409    PARTIAL      BROWN          ONE   PENDANT            YELLOW   \n",
      "8410    PARTIAL      BROWN          ONE   PENDANT             BROWN   \n",
      "8411    PARTIAL      BROWN          ONE   PENDANT             BROWN   \n",
      "8412    PARTIAL      BROWN          ONE   PENDANT            ORANGE   \n",
      "8413    PARTIAL      BROWN          ONE   PENDANT            ORANGE   \n",
      "8414    PARTIAL      BROWN          ONE   PENDANT              BUFF   \n",
      "8415    PARTIAL      BROWN          ONE   PENDANT              BUFF   \n",
      "\n",
      "     population habitat  \n",
      "0       SEVERAL   WOODS  \n",
      "1       SEVERAL   WOODS  \n",
      "2       SEVERAL   WOODS  \n",
      "3       SEVERAL   WOODS  \n",
      "4       SEVERAL   WOODS  \n",
      "5       SEVERAL   WOODS  \n",
      "6       SEVERAL   WOODS  \n",
      "7       SEVERAL   WOODS  \n",
      "8       SEVERAL   WOODS  \n",
      "9       SEVERAL   WOODS  \n",
      "10      SEVERAL   WOODS  \n",
      "11      SEVERAL   WOODS  \n",
      "12      SEVERAL   WOODS  \n",
      "13      SEVERAL   WOODS  \n",
      "14      SEVERAL   WOODS  \n",
      "15      SEVERAL   WOODS  \n",
      "16      SEVERAL   WOODS  \n",
      "17      SEVERAL   WOODS  \n",
      "18      SEVERAL   WOODS  \n",
      "19      SEVERAL   WOODS  \n",
      "20      SEVERAL   WOODS  \n",
      "21      SEVERAL   WOODS  \n",
      "22      SEVERAL   WOODS  \n",
      "23      SEVERAL   WOODS  \n",
      "24      SEVERAL   WOODS  \n",
      "25      SEVERAL   WOODS  \n",
      "26      SEVERAL   WOODS  \n",
      "27      SEVERAL   WOODS  \n",
      "28      SEVERAL   WOODS  \n",
      "29      SEVERAL   WOODS  \n",
      "...         ...     ...  \n",
      "8386    SEVERAL  LEAVES  \n",
      "8387  CLUSTERED  LEAVES  \n",
      "8388    SEVERAL  LEAVES  \n",
      "8389  CLUSTERED  LEAVES  \n",
      "8390    SEVERAL  LEAVES  \n",
      "8391  CLUSTERED  LEAVES  \n",
      "8392    SEVERAL  LEAVES  \n",
      "8393  CLUSTERED  LEAVES  \n",
      "8394    SEVERAL  LEAVES  \n",
      "8395  CLUSTERED  LEAVES  \n",
      "8396    SEVERAL  LEAVES  \n",
      "8397  CLUSTERED  LEAVES  \n",
      "8398    SEVERAL  LEAVES  \n",
      "8399  CLUSTERED  LEAVES  \n",
      "8400    SEVERAL  LEAVES  \n",
      "8401  CLUSTERED  LEAVES  \n",
      "8402    SEVERAL  LEAVES  \n",
      "8403  CLUSTERED  LEAVES  \n",
      "8404    SEVERAL  LEAVES  \n",
      "8405  CLUSTERED  LEAVES  \n",
      "8406    SEVERAL  LEAVES  \n",
      "8407  CLUSTERED  LEAVES  \n",
      "8408    SEVERAL  LEAVES  \n",
      "8409  CLUSTERED  LEAVES  \n",
      "8410    SEVERAL  LEAVES  \n",
      "8411  CLUSTERED  LEAVES  \n",
      "8412    SEVERAL  LEAVES  \n",
      "8413  CLUSTERED  LEAVES  \n",
      "8414    SEVERAL  LEAVES  \n",
      "8415  CLUSTERED  LEAVES  \n",
      "\n",
      "[8416 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "##Read the file from Current directory\n",
    "\n",
    "df = pd.read_csv('mushroom1.csv')\n",
    "\n",
    "print(df)\n",
    "\n",
    "#could also have used read_table and specifying the delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0        1       2       3\n",
      "0   EDIBLE   CONVEX  SMOOTH     NaN\n",
      "1   EDIBLE   CONVEX  SMOOTH     NaN\n",
      "2   EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "3   EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "4   EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "5   EDIBLE      NaN  SMOOTH   WHITE\n",
      "6   EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "7   EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "8   EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "9   EDIBLE  CONVEX2  SMOOTH   WHITE\n",
      "10  EDIBLE  CONVEX1  SMOOTH  WHITE1\n"
     ]
    }
   ],
   "source": [
    "#A file will not always have a header row\n",
    "\n",
    "df2 = pd.read_csv('mushroom2.csv',header = None)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      col1     col2    col3    col4\n",
      "0   EDIBLE   CONVEX  SMOOTH     NaN\n",
      "1   EDIBLE   CONVEX  SMOOTH     NaN\n",
      "2   EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "3   EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "4   EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "5   EDIBLE      NaN  SMOOTH   WHITE\n",
      "6   EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "7   EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "8   EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "9   EDIBLE  CONVEX2  SMOOTH   WHITE\n",
      "10  EDIBLE  CONVEX1  SMOOTH  WHITE1\n"
     ]
    }
   ],
   "source": [
    "#you have a couple of options. You can allow pandas to assign default column names, or you can specify names yourself:\n",
    "df2 = pd.read_csv('mushroom2.csv',\n",
    "                  names = ['col1','col2','col3','col4'] )\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           col2    col3    col4\n",
      "col1                           \n",
      "EDIBLE   CONVEX  SMOOTH     NaN\n",
      "EDIBLE   CONVEX  SMOOTH     NaN\n",
      "EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "EDIBLE      NaN  SMOOTH   WHITE\n",
      "EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "EDIBLE  CONVEX2  SMOOTH   WHITE\n",
      "EDIBLE  CONVEX1  SMOOTH  WHITE1\n"
     ]
    }
   ],
   "source": [
    "#Suppose you want the col1 to be indexed:\n",
    "df2 = pd.read_csv('mushroom2.csv',\n",
    "                  names = ['col1','col2','col3','col4'],\n",
    "                  index_col = 'col1')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           col2    col3    col4\n",
      "col1                           \n",
      "EDIBLE   CONVEX  SMOOTH     NaN\n",
      "EDIBLE   CONVEX  SMOOTH     NaN\n",
      "EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "EDIBLE      NaN  SMOOTH   WHITE\n",
      "EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "EDIBLE   CONVEX  SMOOTH   WHITE\n",
      "EDIBLE  CONVEX2  SMOOTH   WHITE\n",
      "EDIBLE  CONVEX1  SMOOTH  WHITE1\n"
     ]
    }
   ],
   "source": [
    "# Handling Missing Values\n",
    "\n",
    "\n",
    "df3 = pd.read_csv('mushroom2.csv',\n",
    "                  names = ['col1','col2','col3','col4'],\n",
    "                  index_col = 'col1')\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          col2    col3   col4\n",
      "col1                         \n",
      "EDIBLE  CONVEX  SMOOTH    NaN\n",
      "EDIBLE  CONVEX  SMOOTH    NaN\n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "EDIBLE     NaN  SMOOTH  WHITE\n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "EDIBLE     NaN  SMOOTH  WHITE\n",
      "EDIBLE     NaN  SMOOTH    NaN\n"
     ]
    }
   ],
   "source": [
    "#Different NA sentinels can be specified for each column in a dict:\n",
    "\n",
    "sentinels = {'col2': ['CONVEX1','CONVEX2'], 'col4': ['WHITE1']}\n",
    "df4 = pd.read_csv('mushroom2.csv',\n",
    "                  names = ['col1','col2','col3','col4'],\n",
    "                  index_col = 'col1',\n",
    "                 na_values=sentinels)\n",
    "print(df4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          col2    col3   col4\n",
      "col1                         \n",
      "EDIBLE  CONVEX  SMOOTH    NaN\n",
      "EDIBLE  CONVEX  SMOOTH    NaN\n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n"
     ]
    }
   ],
   "source": [
    "#If you want to only read out a small number of rows (avoiding reading the entire file),\n",
    "#specify that with nrows:\n",
    "\n",
    "df5 = pd.read_csv('mushroom2.csv',\n",
    "                  names = ['col1','col2','col3','col4'],\n",
    "                  index_col = 'col1',\n",
    "                 na_values=sentinels,\n",
    "                  nrows = 5)\n",
    "print(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Analytics\\Personal\\Machine Learning\\Training\\R\\Dataset\n",
      "<pandas.io.parsers.TextFileReader object at 0x0000027AF6BF4940>\n",
      "<class 'pandas.io.parsers.TextFileReader'>\n"
     ]
    }
   ],
   "source": [
    "#To read out a file in pieces, specify a chunksize as a number of rows:\n",
    "\n",
    "chunker = pd.read_csv('mushroom2.csv',\n",
    "                  names = ['col1','col2','col3','col4'],\n",
    "                  index_col = 'col1',\n",
    "                 #na_values=sentinels,\n",
    "                      chunksize=2)\n",
    "print(chunker)\n",
    "#print(type(chunker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          col2    col3  col4\n",
      "col1                        \n",
      "EDIBLE  CONVEX  SMOOTH   NaN\n",
      "EDIBLE  CONVEX  SMOOTH   NaN\n",
      "          col2    col3   col4\n",
      "col1                         \n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "          col2    col3   col4\n",
      "col1                         \n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "EDIBLE     NaN  SMOOTH  WHITE\n",
      "          col2    col3   col4\n",
      "col1                         \n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "          col2    col3   col4\n",
      "col1                         \n",
      "EDIBLE  CONVEX  SMOOTH  WHITE\n",
      "EDIBLE     NaN  SMOOTH  WHITE\n",
      "        col2    col3  col4\n",
      "col1                      \n",
      "EDIBLE   NaN  SMOOTH   NaN\n"
     ]
    }
   ],
   "source": [
    "#The TextParser object returned by read_csv allows you to iterate over the parts of the\n",
    "#file according to the chunksize\n",
    "\n",
    "\n",
    "for piece in chunker:\n",
    "    print(piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing Data Out to Text Format\n",
    "df5.to_csv('Pythonoutput.csv')\n",
    "df5.to_csv('Pythonoutput.txt',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1|col2|col3|col4\n",
      "EDIBLE|CONVEX|SMOOTH|\n",
      "EDIBLE|CONVEX|SMOOTH|\n",
      "EDIBLE|CONVEX|SMOOTH|WHITE\n",
      "EDIBLE|CONVEX|SMOOTH|WHITE\n",
      "EDIBLE|CONVEX|SMOOTH|WHITE\n"
     ]
    }
   ],
   "source": [
    "#Other delimiters can be used (writing to sys.stdout so it just prints the text result\n",
    "import sys \n",
    "\n",
    "df5.to_csv(sys.stdout, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1|col2|col3|col4\n",
      "EDIBLE|CONVEX|SMOOTH|NULL\n",
      "EDIBLE|CONVEX|SMOOTH|NULL\n",
      "EDIBLE|CONVEX|SMOOTH|WHITE\n",
      "EDIBLE|CONVEX|SMOOTH|WHITE\n",
      "EDIBLE|CONVEX|SMOOTH|WHITE\n"
     ]
    }
   ],
   "source": [
    "#Missing values appear as empty strings in the output. You might want to denote them\n",
    "#by some other sentinel value:\n",
    "\n",
    "df5.to_csv(sys.stdout, sep='|',na_rep='NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDIBLE|CONVEX|SMOOTH|NULL\n",
      "EDIBLE|CONVEX|SMOOTH|NULL\n",
      "EDIBLE|CONVEX|SMOOTH|WHITE\n",
      "EDIBLE|CONVEX|SMOOTH|WHITE\n",
      "EDIBLE|CONVEX|SMOOTH|WHITE\n"
     ]
    }
   ],
   "source": [
    "#column labels can be disabled\n",
    "\n",
    "df5.to_csv(sys.stdout, sep='|',na_rep='NULL', header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1|col1|col2|col3\n",
      "EDIBLE|NULL|CONVEX|SMOOTH\n",
      "EDIBLE|NULL|CONVEX|SMOOTH\n",
      "EDIBLE|NULL|CONVEX|SMOOTH\n",
      "EDIBLE|NULL|CONVEX|SMOOTH\n",
      "EDIBLE|NULL|CONVEX|SMOOTH\n"
     ]
    }
   ],
   "source": [
    "#You can also write only a subset of the columns, and in an order of your choosing:\n",
    "df5.to_csv(sys.stdout, sep='|',na_rep='NULL',columns=['col1','col2','col3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
